
server.sources = static_log_source 
server.channels = hdfs_channel
server.sinks = hdfs_sink

server.sources.static_log_source.type = spooldir
server.sources.static_log_source.spoolDir = /srv/BigData/hadoop/data1/flume_pool/log_to_hdfs/Flume_Encoded/Log_Online_1
server.sources.static_log_source.fileSuffix = .COMPLETED
server.sources.static_log_source.ignorePattern = ^$
server.sources.static_log_source.trackerDir = /srv/BigData/hadoop/data2/flume_pool/log_to_hdfs/Log_Online_1/tracker
server.sources.static_log_source.maxBlobLength = 16384
server.sources.static_log_source.batchSize = 10000
server.sources.static_log_source.inputCharset = UTF-8
server.sources.static_log_source.deserializer = LINE
server.sources.static_log_source.deserializer.maxBatchLine = 10
server.sources.static_log_source.deserializer.maxLineLength = 102400
server.sources.static_log_source.selector.type = replicating
server.sources.static_log_source.fileHeaderKey = file
server.sources.static_log_source.fileHeader = false
server.sources.static_log_source.basenameHeader = true
server.sources.static_log_source.basenameHeaderKey = basename
server.sources.static_log_source.deletePolicy = never

server.channels.hdfs_channel.type = file
server.channels.hdfs_channel.capacity = 100000
server.channels.hdfs_channel.write-timeout = 1
server.channels.hdfs_channel.transactionCapacity = 10000
server.channels.hdfs_channel.maxFileSize = 2146435071
server.channels.hdfs_channel.minimumRequiredSpace = 524288000
server.channels.hdfs_channel.dataDirs = /srv/BigData/hadoop/data2/filechannel/hdfs_channel/dataDirs,/srv/BigData/hadoop/data1/filechannel/hdfs_channel/dataDirs/srv/BigData/hadoop/data3/filechannel/hdfs_channel/dataDirs
server.channels.hdfs_channel.checkpointDir = /srv/BigData/hadoop/data2/filechannel/hdfs_channel/checkpoint
server.channels.hdfs_channel.keep-alive = 10

server.sinks.hdfs_sink.type = hdfs
server.sinks.hdfs_sink.hdfs.inUsePrefix = TMP_
server.sinks.hdfs_sink.hdfs.filePrefix = over_%{basename}
server.sinks.hdfs_sink.hdfs.fileNameUseTimeStamp = false
server.sinks.hdfs_sink.hdfs.fileType = DataStream
server.sinks.hdfs_sink.hdfs.writeFormat = Writable
server.sinks.hdfs_sink.hdfs.callTimeout = 10000
server.sinks.hdfs_sink.hdfs.codeC =
server.sinks.hdfs_sink.hdfs.round = false
server.sinks.hdfs_sink.hdfs.roundUnit = second
server.sinks.hdfs_sink.hdfs.rollCount = 0
server.sinks.hdfs_sink.hdfs.rollSize = 0
server.sinks.hdfs_sink.hdfs.rollInterval = 0
server.sinks.hdfs_sink.hdfs.rollTimerPoolSize = 1
server.sinks.hdfs_sink.hdfs.kerberosPrincipal = flume
server.sinks.hdfs_sink.hdfs.kerberosKeytab = /opt/huawei/Bigdata/FusionInsight/FusionInsight-Flume-1.6.0/flume/conf/flume.keytab
server.sinks.hdfs_sink.hdfs.fileSuffix =
server.sinks.hdfs_sink.hdfs.useLocalTimeStamp = true
server.sinks.hdfs_sink.hdfs.fileCloseByEndEvent = true
server.sinks.hdfs_sink.hdfs.maxOpenFiles = 5000
server.sinks.hdfs_sink.hdfs.minBlockReplicas = 0
server.sinks.hdfs_sink.hdfs.idleTimeout = 0
server.sinks.hdfs_sink.serializer = TEXT
server.sinks.hdfs_sink.serializer.appendNewline = true
server.sinks.hdfs_sink.hdfs.roundValue = 1
server.sinks.hdfs_sink.hdfs.batchSize = 10000
server.sinks.hdfs_sink.hdfs.threadsPoolSize = 1000
server.sinks.hdfs_sink.hdfs.path = hdfs://hacluster/flume/zb

server.sinks.hdfs_sink.channel = hdfs_channel
server.sources.static_log_source.channels = hdfs_channel
