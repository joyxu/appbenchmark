server.sources = static_log_source
server.channels = hdfs_channel    
server.sinks = kafka_sink

server.sources.static_log_source.type = spooldir    
server.sources.static_log_source.spoolDir = /srv/BigData/hadoop/data1/flume_pool/log_to_hdfs/Flume_Encoded/Log_Online_1    
server.sources.static_log_source.fileSuffix = .COMPLETED    
server.sources.static_log_source.ignorePattern = ^$    
server.sources.static_log_source.trackerDir = /srv/BigData/hadoop/data2/flume_pool/log_to_hdfs/Log_Online_1/tracker    
server.sources.static_log_source.maxBlobLength = 16384    
server.sources.static_log_source.batchSize = 10000    
server.sources.static_log_source.inputCharset = UTF-8    
server.sources.static_log_source.deserializer = LINE    
server.sources.static_log_source.deserializer.maxBatchLine = 10    
server.sources.static_log_source.deserializer.maxLineLength = 102400    
server.sources.static_log_source.selector.type = replicating    
server.sources.static_log_source.fileHeaderKey = file    
server.sources.static_log_source.fileHeader = false    
server.sources.static_log_source.basenameHeader = true    
server.sources.static_log_source.basenameHeaderKey = basename    
server.sources.static_log_source.deletePolicy = never

server.channels.hdfs_channel.type = memory    
server.channels.hdfs_channel.capacity = 100000    
server.channels.hdfs_channel.transactionCapacity = 10000

server.sinks.kafka_sink.type = org.apache.flume.sink.kafka.KafkaSink    
server.sinks.kafka_sink.topic = test1    
server.sinks.kafka_sink.brokerList = 192.168.150.4:21005,192.168.150.5:21005,192.168.150.6:21005    
server.sinks.kafka_sink.requiredAcks = 1    
server.sinks.kafka_sink.batchSize = 10000
server.sinks.kafka_sink.channel = hdfs_channel    
server.sources.static_log_source.channels = hdfs_channel
